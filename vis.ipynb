{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87d6fd6-0e04-40fd-9a2e-9b61315c21c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pose estimation dataset...\n",
      "Found 9 videos in /root/autodl-tmp/shiqian/datasets/Ty_data\n",
      "Loading reference view dataset...\n",
      "Found 64 views in /root/autodl-tmp/shiqian/code/gripper/render_random\n",
      "Loading reference view dataset...\n",
      "Found 840 views in /root/autodl-tmp/shiqian/code/gripper/render_lowres\n",
      "Initializing DinoV2 Matcher...\n",
      "Preprocessing reference views...\n",
      "Reference view features obtained\n",
      "DinoV2 Matcher done initialized\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from ty_datasets import PoseDataset, TrackingDataset\n",
    "from ref_dataset import ReferenceDataset, SimTestDataset\n",
    "from matcher import Dinov2Matcher\n",
    "from utils.spd import sample_points_from_mesh\n",
    "\n",
    "B = 1\n",
    "shuffle = False\n",
    "device = 'cuda:3'\n",
    "\n",
    "vis_dataset = PoseDataset() # sample\n",
    "vis_dataset = SimTestDataset(features=True)\n",
    "ref_dataset = ReferenceDataset(dataset_location=\"/root/autodl-tmp/shiqian/code/gripper/render_64views\", features=True)      # 用于matcher的refs\n",
    "vis_dataloader = DataLoader(vis_dataset, batch_size=B, shuffle=shuffle)\n",
    "ref_dataloader = DataLoader(ref_dataset, batch_size=1, shuffle=shuffle)\n",
    "iterloader = iter(vis_dataloader)\n",
    "refs = next(iter(ref_dataloader))\n",
    "\n",
    "global_step = 0\n",
    "gripper_path = \"/root/autodl-tmp/shiqian/code/gripper/franka_hand_obj/franka_hand.obj\"\n",
    "gripper_pointcloud = sample_points_from_mesh(gripper_path, n_pts=8192)\n",
    "matcher = Dinov2Matcher(refs=refs, model_pointcloud=gripper_pointcloud, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c56d7a-ae03-4dcb-ac73-87861c0f84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sample = next(iterloader)\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "rgbs = torch.Tensor(sample['rgb']).float().permute(0, 3, 1, 2).to(device) # B, C, H, W\n",
    "depths = torch.Tensor(sample['depth']).float().permute(0, 3, 1, 2).to(device)\n",
    "masks = torch.Tensor(sample['mask']).float().permute(0, 3, 1, 2).to(device)\n",
    "#kptss = sample['kpts']\n",
    "#npys = sample['npy']\n",
    "#intrinsics = sample['intrinsics']\n",
    "\n",
    "images = torch.concat([rgbs, depths[:,0:1], masks[:,0:1]], axis = 1)\n",
    "# matches_3d = matcher.match_and_fuse(images)  # N, 6 部分实际图中的点 及 算出来的模型中相似度最高的对应点云的坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c39368e-e5f3-4e05-8b9f-c7106f38c7d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.28 GiB. GPU 3 has a total capacity of 23.69 GiB of which 361.69 MiB is free. Process 11443 has 23.33 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1023.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m N_tokens \u001b[38;5;241m=\u001b[39m feat_H \u001b[38;5;241m*\u001b[39m feat_W\n\u001b[1;32m     16\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, feat_C) \u001b[38;5;66;03m# B*N, C\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m ref_features \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_C\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# N_refs*N, C\u001b[39;00m\n\u001b[1;32m     18\u001b[0m cosine_sims \u001b[38;5;241m=\u001b[39m pairwise_cosine_similarity(features, ref_features) \u001b[38;5;66;03m# B*N, 32*N    # 渲染N_refs个视角后，对实际图的所有patch和渲染视角的patch求相似度，试图找出相似度最高的点\u001b[39;00m\n\u001b[1;32m     19\u001b[0m cosine_sims \u001b[38;5;241m=\u001b[39m cosine_sims\u001b[38;5;241m.\u001b[39mreshape(B, N_tokens, N_refs, N_tokens) \u001b[38;5;66;03m# B, 1024, 32, 1024    前面是实际，后面是渲染\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.28 GiB. GPU 3 has a total capacity of 23.69 GiB of which 361.69 MiB is free. Process 11443 has 23.33 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1023.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional import pairwise_cosine_similarity, pairwise_euclidean_distance\n",
    "import torch.nn.functional as F\n",
    "from utils.spd import get_2dbboxes, create_3dmeshgrid, transform_batch_pointcloud_torch\n",
    "from utils.spd import save_pointcloud, transform_pointcloud_torch, project_points, calc_coords_3d_var\n",
    "import math\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "B, C, H, W = images.shape\n",
    "N_refs, feat_C, feat_H, feat_W = matcher.ref_features.shape    # N_refs个视角渲染的特征,直接用预训练好的dinoV2模型\n",
    "assert(feat_H == feat_W)\n",
    "feat_size = feat_H\n",
    "cropped_rgbs, cropped_masks, bboxes = matcher.prepare_images(images)   # 裁一下\n",
    "#features = matcher.extract_features(cropped_rgbs) # B, 1024, 32, 32    #\n",
    "features = torch.tensor(sample['feat']).float().to(device)\n",
    "N_tokens = feat_H * feat_W\n",
    "features = features.permute(0, 2, 3, 1).reshape(-1, feat_C) # B*N, C\n",
    "ref_features = matcher.ref_features.permute(0, 2, 3, 1).reshape(-1, feat_C) # N_refs*N, C\n",
    "cosine_sims = pairwise_cosine_similarity(features, ref_features) # B*N, 32*N    # 渲染N_refs个视角后，对实际图的所有patch和渲染视角的patch求相似度，试图找出相似度最高的点\n",
    "cosine_sims = cosine_sims.reshape(B, N_tokens, N_refs, N_tokens) # B, 1024, 32, 1024    前面是实际，后面是渲染\n",
    "cosine_sims = cosine_sims.reshape(B, feat_H, feat_W, N_refs, feat_H, feat_W) # B, 32, 32, Nref, 32, 32\n",
    "batch_feat_masks = F.interpolate(cropped_masks, size=(feat_H, feat_W), mode = \"nearest\") # B, 1, 32, 32  resize裁剪后实际图的mask\n",
    "\n",
    "cosine_sims = cosine_sims[batch_feat_masks[:,0] > 0]    # 取实际图的mask\n",
    "test_idxs = create_3dmeshgrid(B, feat_H, feat_W, matcher.device)\n",
    "test_idxs = test_idxs[batch_feat_masks[:,0] > 0]    # 对实际图mask后，剩下的patch的坐标\n",
    "\n",
    "#selected_refs = matcher.select_refs(features,batch_feat_masks,B,test_idxs).reshape(-1)    # b,10 -> 10  TODO 现在只能batch=1\n",
    "\n",
    "#select_mask = torch.zeros_like(matcher.feat_masks,device=matcher.device)\n",
    "#select_mask[selected_refs] = 1\n",
    "#feat_masks = matcher.feat_masks * select_mask\n",
    "feat_masks = matcher.feat_masks\n",
    "\n",
    "cosine_sims = cosine_sims[:, feat_masks[:,0] > 0]  # 取渲染图的mask\n",
    "ref_idxs = create_3dmeshgrid(N_refs, feat_H, feat_W, matcher.device)\n",
    "ref_idxs = ref_idxs[feat_masks[:,0] > 0]       # 对渲染图mask后，剩下的patch的坐标\n",
    "\n",
    "test_2d_coords = matcher.idx_to_2d_coords(test_idxs, bboxes) # N_test_2d_pts, 3    还原到原图像中的位置\n",
    "ref_2d_coords = matcher.idx_to_2d_coords(ref_idxs, matcher.ref_bboxes)\n",
    "ref_3d_coords = matcher.coords_2d_to_3d(ref_2d_coords, matcher.ref_images[:,3], matcher.ref_intrinsics, matcher.ref_c2os)   # 找到参考图中的点，在三维模型中的位置\n",
    "\n",
    "print(ref_3d_coords.shape)\n",
    "\n",
    "ref_valid_idxs = torch.logical_and(ref_3d_coords[:,1]<10, ref_3d_coords[:,1]>-10) # ref的三维坐标在-1到1之间？\n",
    "ref_valid_idxs = torch.logical_and(ref_valid_idxs, ref_3d_coords[:,2]<10)\n",
    "ref_valid_idxs = torch.logical_and(ref_valid_idxs, ref_3d_coords[:,2]>-10)\n",
    "ref_valid_idxs = torch.logical_and(ref_valid_idxs, ref_3d_coords[:,3]<10)\n",
    "ref_valid_idxs = torch.logical_and(ref_valid_idxs, ref_3d_coords[:,3]>-10)\n",
    "\n",
    "cosine_sims = cosine_sims[:, ref_valid_idxs] # N_test_2d_pts, N_3d_ref_pts 594,19938\n",
    "ref_3d_coords = ref_3d_coords[ref_valid_idxs]    # 19938，3 # 这两行滤去了三维坐标不在-1到1之间的点云\n",
    "\n",
    "print(cosine_sims.shape)\n",
    "sim_threshold = 0\n",
    "num_good_sims = torch.sum(cosine_sims > sim_threshold, dim = 1)\n",
    "good_pts = num_good_sims > 5 #Shape N_2d_pts\n",
    "cosine_sims = cosine_sims[good_pts]\n",
    "test_2d_coords = test_2d_coords[good_pts]\n",
    "print(cosine_sims.shape)\n",
    "\n",
    "ref_3d_coords_1 = ref_3d_coords.unsqueeze(0).repeat(cosine_sims.shape[0], 1, 1)\n",
    "test_2d_coords_1 = test_2d_coords.unsqueeze(1).repeat(1, cosine_sims.shape[1], 1)\n",
    "cosine_sim_coords = torch.concat([test_2d_coords_1, ref_3d_coords_1], axis=2)\n",
    "sims_and_coords = torch.concat([cosine_sims.unsqueeze(2), cosine_sim_coords], axis=2) # N_test_2d_pts, N_3d_ref_pts, 8 (sim, batchid, x, y, refid, x, y, z)\n",
    "\n",
    "#print(sims_and_coords.shape)\n",
    "#target_point_vars = calc_coords_3d_var(sims_and_coords, sim_threshold)\n",
    "#var_threshold = 0.01\n",
    "\n",
    "        \n",
    "'''\n",
    "dists_3d = pairwise_euclidean_distance(matcher.model_pc, ref_3d_coords).float() # N_pts, N_ref_pts 模型的点云和所有渲染出的3d点云的距离\n",
    "# Generate similarity field. We want shape N_pts, N_test_2d_pts\n",
    "gaussian_var = 0.0001\n",
    "gaussian_coeff = (1.0 / (gaussian_var*(math.sqrt(2*3.14159265)))) * torch.exp(-0.5 * torch.square(dists_3d / gaussian_var)) # N_pts, N_ref_pts 高斯相似度，基于欧氏距离\n",
    "#print(gaussian_coeff.dtype, cosine_sims.dtype, ref_3d_coords.dtype)\n",
    "sim_field = torch.matmul(gaussian_coeff, cosine_sims.permute(1, 0)) / ref_3d_coords.shape[0]    # 高斯相似度*cos-sim ，得到模型与实际图片之间的相似度关系 8192,594\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9730b9-8cb2-4c62-9703-85d26abe65e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_sims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m selectidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m27\u001b[39m    \u001b[38;5;66;03m# 89似乎是一个匹配较好的位置\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# >0.8 96\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(cosine_sims.shape\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Choose by threshold\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m good_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_sims\u001b[49m \u001b[38;5;241m>\u001b[39m threshold \u001b[38;5;66;03m# Bool N_2d_pts, N_3d_pts\u001b[39;00m\n\u001b[1;32m     13\u001b[0m good_coords_3d \u001b[38;5;241m=\u001b[39m ref_3d_coords[good_pairs[selectidx], \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# N,3 numpy\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Choose top N points\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#N = 50\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#coords_3d = ref_3d_coords[:, 1:] # N_3d_pts, 3\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#sorted_sims, sorted_idxs = torch.sort(cosine_sims[selectidx], descending=True) # N_3d_pts, 1\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#good_coords_3d = coords_3d[sorted_idxs[:N]].cpu().numpy() # N, 3\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosine_sims' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN, KMeans\n",
    "\n",
    "threshold = 0.8\n",
    "selectidx = 27    # 89似乎是一个匹配较好的位置\n",
    "# >0.8 96\n",
    "#print(cosine_sims.shape\n",
    "\n",
    "# Choose by threshold\n",
    "good_pairs = cosine_sims > threshold # Bool N_2d_pts, N_3d_pts\n",
    "good_coords_3d = ref_3d_coords[good_pairs[selectidx], 1:].cpu().numpy() # N,3 numpy\n",
    "\n",
    "# Choose top N points\n",
    "#N = 50\n",
    "#coords_3d = ref_3d_coords[:, 1:] # N_3d_pts, 3\n",
    "#sorted_sims, sorted_idxs = torch.sort(cosine_sims[selectidx], descending=True) # N_3d_pts, 1\n",
    "#good_coords_3d = coords_3d[sorted_idxs[:N]].cpu().numpy() # N, 3\n",
    "\n",
    "cluster = DBSCAN(eps = 0.01)\n",
    "labels = cluster.fit(good_coords_3d).labels_\n",
    "\n",
    "unique_labels = set(labels)\n",
    "colors = np.array([plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))])[:,:3]\n",
    "#print(colors)\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "print(\"Total number of points: %d\" % labels.shape[0])\n",
    "print(\"Noise ratio: %.2f\" % (n_noise_ / labels.shape[0]))\n",
    "\n",
    "#point_cloud = np.array(matcher.model_pc.cpu())\n",
    "point_cloud = ref_3d_coords[:,1:].cpu().numpy()\n",
    "\n",
    "#rgb = F.interpolate(cropped_rgbs, size = (32, 32))[0].permute(1,2,0).cpu().numpy()\n",
    "#rgb = ((rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb)) *255.0).astype(int)\n",
    "#rgb[test_idxs[:][1].cpu()][test_idxs[:][2].cpu()] = np.array([255,0,0])\n",
    "rgb = images[0, :3].permute(1, 2, 0).cpu().numpy() / 255.0 # H, W, 3\n",
    "#print(test_2d_coords)\n",
    "#rgb[test_2d_coords[:,1].cpu().numpy(), test_2d_coords[:,2].cpu().numpy()] = np.array([1,0,0])\n",
    "rgb[test_2d_coords[selectidx,1].cpu().numpy(), test_2d_coords[selectidx,2].cpu().numpy()] = np.array([1,0,0])\n",
    "\n",
    "#print(rgb)\n",
    "fig = plt.figure()\n",
    "plt.subplot(1,1, 1)\n",
    "plt.imshow(rgb)\n",
    "plt.axis('off')\n",
    "\n",
    "heatmap = cosine_sims[selectidx].cpu()\n",
    "#heatmap = heatmap/heatmap.max()\n",
    "heatmap = torch.clip(heatmap, min=0, max=1)\n",
    "point_color = np.zeros_like(point_cloud)\n",
    "point_color[:,0] = heatmap\n",
    "point_color[:,2] = 1-heatmap\n",
    "point_color = np.ones_like(point_cloud)\n",
    "\n",
    "\n",
    "print(point_cloud.shape, point_color.shape)\n",
    "heat_mask = heatmap > threshold\n",
    "#heat_mask = sorted_idxs[:N].cpu().numpy()\n",
    "#heat_mask = heatmap > 0\n",
    "#point_cloud = point_cloud[heat_mask]\n",
    "#point_color = point_color[heat_mask]\n",
    "\n",
    "labeled_colors = np.zeros((labels.shape[0], 3))\n",
    "labeled_colors[labels == -1] = np.array([0,0,0])\n",
    "labeled_colors[labels != -1] = colors[labels[labels != -1]]\n",
    "#point_color = labeled_colors\n",
    "point_color[heat_mask] = labeled_colors\n",
    "#print(point_color[heatmap > matcher.threshold][labels != -1])\n",
    "#print(colors[labels[labels != -1]])\n",
    "#print(colors[0])\n",
    "#print(point_cloud[::5])\n",
    "#print(labels[::5])\n",
    "#print(point_color[::5])\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=point_cloud[:, 0],\n",
    "    y=point_cloud[:, 1],\n",
    "    z=point_cloud[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,  # 调整节点的大小\n",
    "        color=point_color,  # 给点云上色\n",
    "        opacity=0.9\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(width=1000, height=1000)\n",
    "fig.update_scenes(aspectmode='data')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "140abaf9-9540-4bcb-9833-834f174695bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0118, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(sim_field[:,230] - sim_field[:,550])  # 确实是不一样的，但是太不明显了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
